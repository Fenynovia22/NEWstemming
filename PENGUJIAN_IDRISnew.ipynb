{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"PENGUJIAN_IDRISnew.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"e7862188","executionInfo":{"status":"ok","timestamp":1628351146307,"user_tz":-420,"elapsed":1943,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["import re\n","import nltk\n","import os\n","import pandas as pd\n","import numpy as np "],"id":"e7862188","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YtEcWJBXEtSp","executionInfo":{"status":"ok","timestamp":1628351162618,"user_tz":-420,"elapsed":16317,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}},"outputId":"1c027869-0515-428d-9f21-cf9cc0d06a3c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"YtEcWJBXEtSp","execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lviL1ebnEvCD","executionInfo":{"status":"ok","timestamp":1628351162619,"user_tz":-420,"elapsed":16,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}},"outputId":"adb428fe-d343-4b1f-c0a4-316759f05302"},"source":["cd '/content/drive/My Drive/Colab Notebooks/data_skripsi'"],"id":"lviL1ebnEvCD","execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/data_skripsi\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FiW_5rFoEx7S","executionInfo":{"status":"ok","timestamp":1628351539625,"user_tz":-420,"elapsed":347,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}},"outputId":"2225ded0-ce04-4f55-a721-8849700f5e29"},"source":["!ls"],"id":"FiW_5rFoEx7S","execution_count":19,"outputs":[{"output_type":"stream","text":[" actual_word\t\t\t   kata_dasar_db.txt\n"," hasil_idris\t\t\t   PENGUJIAN_IDRISnew.ipynb\n"," hasil_inidris\t\t\t   PENGUJIAN_INIDRISnew.ipynb\n","'Hasil perbandingan Idris.csv'\t  'Perbandingan Stemming Idris.csv'\n","'Hasil perbandingan Inidris.csv'  'Perbandingan Stemming Inidris.csv'\n"," IDRIS.ipynb\t\t\t   stopwords2.txt\n"," INIDRIS.ipynb\t\t\t   stopwords.txt\n"," katadasarbahasaindonesia.txt\t   test_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6c702994","executionInfo":{"status":"ok","timestamp":1628351540504,"user_tz":-420,"elapsed":550,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}},"outputId":"0c6ec9bf-77f4-4a7a-c334-052165a5ef4a"},"source":["stopword = open(\"stopwords2.txt\", 'r').read() \n","stopword = stopword.split(\"\\n\")\n","stopword[:5]"],"id":"6c702994","execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ada', 'adalah', 'adanya', 'adapun', 'agak']"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"322b9c77","executionInfo":{"status":"ok","timestamp":1628351540505,"user_tz":-420,"elapsed":14,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}},"outputId":"10c850da-e0a0-4d3a-d107-9c80e25640f0"},"source":["kata_dasar = open(\"kata_dasar_db.txt\", 'r').read()\n","kata_dasar = kata_dasar.split(\"\\n\")\n","\n","kamus = []\n","for i in kata_dasar:\n","    kata = \"{}\".format(i)\n","    kata = kata.replace(\"(Nomina)\", \"\")\n","    kata = kata.replace(\"(Adjektiva)\", \"\")\n","    kata = kata.replace(\"(Adverbia)\", \"\")\n","    kata = kata.replace(\"(Numeralia)\", \"\")\n","    kata = kata.replace(\"(Pronomina)\", \"\")\n","    kata = kata.replace(\"(Verba)\", \"\")\n","    kata = kata.replace(\"(Preposisi)\", \"\")\n","    kata = kata.replace(\"(Interjeksi)\", \"\")\n","    kata = kata.replace(\"(Konjungsi)\", \"\")\n","    kata = kata.replace(\"(Lain-lain)\", \"\")\n","    kata = kata.replace(\"\\n\", \"\")\n","    kata = kata.rstrip()\n","    kamus.append(kata)\n","kamus[:5]"],"id":"322b9c77","execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['a', 'ab', 'aba', 'aba-aba', 'abad']"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"86b81d51","executionInfo":{"status":"ok","timestamp":1628351540505,"user_tz":-420,"elapsed":13,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["# cek kata dasar di kamus\n","def cekKamus_idris(kata):\n","    if kata in kamus:\n","        return kata\n","    else:\n","        status = 0\n","    return status"],"id":"86b81d51","execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"f78b9e84","executionInfo":{"status":"ok","timestamp":1628351540506,"user_tz":-420,"elapsed":13,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["# fungsi untuk menghapus suffix seperti -ku, -mu, -kah, dsb\n","def del_inflection_suffixes_idris(kata):\n","    kataAsal = kata\n","    if(re.search(r\"([kl]ah|pun)$\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"([kl]ah|pun)$\", '', kata, re.IGNORECASE)\n","        if(cekKamus_idris(_kata)):\n","            return _kata\n","        else:\n","            kata = _kata\n","    if(re.search(r'([km]u|nya)$', kata, re.IGNORECASE)):\n","        _kata = re.sub(r'([km]u|nya)$', '', kata, re.IGNORECASE)\n","        if(cekKamus_idris(_kata)):\n","            return _kata\n","    return kataAsal"],"id":"f78b9e84","execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"97f886d8","executionInfo":{"status":"ok","timestamp":1628351540506,"user_tz":-420,"elapsed":11,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["# Cek Prefix Disallowed Sufixes (Kombinasi Awalan dan Akhiran yang tidak diizinkan)\n","def cek_prefix_disallowed_sufiks_idris(kata):\n","    kataAsal = kata\n","    # r\"^(ber)[[:alpha:]](lah|an)$\"\n","    if(re.search(r\"^(ber)[^\\W\\d_](lah|an)$\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"^(ber)\", '', kata, re.IGNORECASE)\n","        return _kata\n","    # ^(men|di|pe|ter)[[:alpha:]](i)\n","    if (re.search(r\"^(men|di|pe|ter)[^\\W\\d_](i)$\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"^(men|di|pe|ter)\", '', kata, re.IGNORECASE)\n","        return _kata\n","    return kataAsal"],"id":"97f886d8","execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"e79581c0","executionInfo":{"status":"ok","timestamp":1628351540507,"user_tz":-420,"elapsed":12,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["# Hapus Derivation Suffixes (\"-i\", \"-an\" atau \"-kan\")\n","def del_derivation_suffixes_idris(kata):\n","    if(re.search(r\"(i|an)$\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"(i|an)$\", '', kata, re.IGNORECASE)\n","        if(cekKamus_idris(_kata)):\n","            return _kata\n","        elif(re.search(r\"(kan)$\", kata)):\n","            _kata = re.sub(r\"(kan)$\", '', kata, re.IGNORECASE)\n","            if(cekKamus_idris(_kata)):\n","                return _kata\n","            else:\n","                _kata = del_derivation_prefix_idris(_kata)\n","                return _kata"],"id":"e79581c0","execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"70530184","executionInfo":{"status":"ok","timestamp":1628351540507,"user_tz":-420,"elapsed":11,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["# Hapus Derivation Prefix (\"di-\", \"ke-\", \"se-\", \"te-\", \"be-\", \"me-\", atau \"pe-\")\n","def del_derivation_prefix_idris(kata):\n","    kataAsal = kata\n","    if(re.search(r\"^(diper)\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"^(diper)\", '', kata, re.IGNORECASE)\n","        return _kata\n","\n","    if(re.search(r\"^(di|[ks]e)\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"^(di|[ks]e)\", '', kata, re.IGNORECASE)\n","        return _kata\n","\n","    if(re.search(r\"^(ke[bt]er)\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"^(ke[bt]er)\", '', kata, re.IGNORECASE)\n","        return _kata\n","\n","    if(re.search(r\"^([bt]e)\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"^([bt]e[lr])\", '', kata, re.IGNORECASE)\n","        if(cekKamus_idris(_kata)):\n","            return _kata\n","        _kata = re.sub(r\"^([bt]e)\", '', kata, re.IGNORECASE)\n","        return _kata\n","\n","    if(re.search(r\"^([mp]e)\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"^([mp]e)\", '', kata, re.IGNORECASE)\n","        if(cekKamus_idris(_kata)):\n","            return _kata\n","        else:\n","            if(re.search(r\"^(memper)\", kata, re.IGNORECASE)):\n","                _kata = re.sub(r\"^(memper)\", '', kata, re.IGNORECASE)\n","                if(cekKamus_idris(_kata)):\n","                    return _kata\n","\n","            if(re.search(r\"^([mp]eng)\", kata, re.IGNORECASE)):\n","                _kata = re.sub(r\"^([mp]eng)\", '', kata, re.IGNORECASE)\n","                if(cekKamus_idris(_kata)):\n","                    return _kata\n","                else:\n","                    _kata = re.sub(r\"([mp]eng)\", 'k', kata, re.IGNORECASE)\n","\n","            if(re.search(r\"^([mp]eny)\", kata, re.IGNORECASE)):\n","                _kata = re.sub(r\"^([mp]eny)\", 's', kata, re.IGNORECASE)\n","\n","            if(re.search(r\"^([mp]e[lr])\", kata, re.IGNORECASE)):\n","                _kata = re.sub(r\"^([mp]e[lr])\", '', kata, re.IGNORECASE)\n","\n","            if(re.search(r\"^([mp]en)\", kata, re.IGNORECASE)):\n","                _kata = re.sub(r\"^([mp]en)\", 't', kata, re.IGNORECASE)\n","                if(cekKamus_idris(_kata)):\n","                    return _kata\n","                else:\n","                    _kata = re.sub(r\"^([mp]en)\", '', kata, re.IGNORECASE)\n","\n","            if(re.search(r\"^([mp]em)\", kata, re.IGNORECASE)):\n","                _kata = re.sub(r\"^([mp]em)\", '', kata, re.IGNORECASE)\n","                if(cekKamus_idris(_kata)):\n","                    return _kata\n","                else:\n","                    _kata = re.sub(r\"^([mp]em)\", 'p', kata, re.IGNORECASE)\n","\n","            return _kata\n","    return kataAsal"],"id":"70530184","execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"6f37e7b6","executionInfo":{"status":"ok","timestamp":1628351540508,"user_tz":-420,"elapsed":12,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["def step2_idris(kata):\n","    kataAsal = kata\n","    kata = cek_prefix_disallowed_sufiks_idris(kata)\n","    if(cekKamus_idris(kata)):\n","        return kata\n","    else:\n","        kata = del_derivation_prefix_idris(kata)\n","        if(cekKamus_idris(kata)):\n","            return kata\n","        else:\n","            kata = del_inflection_suffixes_idris(kata)\n","            if(cekKamus_idris(kata)):\n","                return kata\n","            else:\n","                kata = del_derivation_suffixes_idris(kata)\n","                # print(\"4\"+str(kata))\n","                if(cekKamus_idris(kata)):\n","                    return kata\n","                else:\n","                    return kataAsal+\" \"+\"(Kata Salah)\""],"id":"6f37e7b6","execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"23b39b61","executionInfo":{"status":"ok","timestamp":1628351540508,"user_tz":-420,"elapsed":11,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["def stemming_idris(kata):\n","    kataAsal = kata\n","    # cekKamus = cekKamus_idris(kata)\n","    if (cekKamus_idris(kata) != 0):\n","        return kata\n","    else:\n","        kata = step2_idris(kata)\n","        return kata"],"id":"23b39b61","execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"caedd722"},"source":["## CASE FOLDING"],"id":"caedd722"},{"cell_type":"code","metadata":{"scrolled":true,"id":"7d720df2","executionInfo":{"status":"ok","timestamp":1628351540509,"user_tz":-420,"elapsed":12,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["def Case_folding(casefold):\n","    casefold = casefold.lower()\n","    # Remove angka termasuk angka yang berada dalam string\n","    # Remove non ASCII chars\n","    casefold = re.sub(r'[^\\x00-\\x7f]', r'', casefold)\n","    casefold = re.sub(r'(\\\\u[0-9A-Fa-f]+)', r'', casefold)\n","    casefold = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", casefold)\n","    casefold = re.sub(r'\\\\u\\w\\w\\w\\w', '', casefold)\n","    # Remove link web\n","    casefold = re.sub(r'http\\S+', '', casefold)\n","    # Remove @username\n","    casefold = re.sub('@[^\\s]+', '', casefold)\n","    # Remove #tagger\n","    casefold = re.sub(r'#([^\\s]+)', '', casefold)\n","    # Remove simbol, angka dan karakter aneh\n","    casefold = re.sub(r\"[.,:;+!\\-_<^/=?\\\"'\\(\\)\\d\\*]\", \" \", casefold)\n","    return casefold"],"id":"7d720df2","execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"70ec57f0"},"source":["## TOKENIZING"],"id":"70ec57f0"},{"cell_type":"code","metadata":{"scrolled":true,"id":"606f9e24","executionInfo":{"status":"ok","timestamp":1628351540509,"user_tz":-420,"elapsed":12,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["# Tokenizing = Kata.split()\n","# print(Tokenizing)"],"id":"606f9e24","execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5a61c0a9"},"source":["## STOPWORD REMOVING"],"id":"5a61c0a9"},{"cell_type":"code","metadata":{"scrolled":true,"id":"4bc4fb61","executionInfo":{"status":"ok","timestamp":1628351540511,"user_tz":-420,"elapsed":13,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["def removeStopword(remove_stop):\n","    Stopword_data = open('stopwords2.txt', 'r').read().split()\n","    Kata_baru = []\n","    content = []\n","    filteredtext = [word for word in remove_stop if word not in Stopword_data]\n","    content.append(\" \".join(filteredtext))\n","    remove_stop = content\n","    return remove_stop"],"id":"4bc4fb61","execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0b7f9747"},"source":["## FUNGSI PERBANDINGAN HASIL"],"id":"0b7f9747"},{"cell_type":"code","metadata":{"id":"043d5204","executionInfo":{"status":"ok","timestamp":1628351540512,"user_tz":-420,"elapsed":14,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["def create_output(string_split, hasil_stem, actual_word, filename):\n","    #membuat dataframe dengan nama kolom dibawah ini\n","    df = pd.DataFrame(columns =  [\"Kata Asli\", \"Stemming Idris\", \"Stemming Asli\", \"Hasil\"])\n","    for i in range(len(string_split)):\n","        #jika kata tersebut adalah kata asing, nama kota, nama orang dsb\n","        if '(' in actual_word[i] and string_split[i] == hasil_stem[i] and hasil_stem[i] == actual_word[i][:actual_word[i].find('(')]:\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Idris':hasil_stem[i], 'Stemming Asli':actual_word[i][:actual_word[i].find('(')], 'Hasil':'Bukan Kata Berimbuhan'}\n","            df = df.append(new_row, ignore_index=True)\n","        \n","        elif'(' in actual_word[i] and string_split[i] == hasil_stem[i] and hasil_stem[i] != actual_word[i][:actual_word[i].find('(')]:\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Idris':hasil_stem[i], 'Stemming Asli':actual_word[i][:actual_word[i].find('(')], 'Hasil':'Unchange'}\n","            df = df.append(new_row, ignore_index=True)\n","            \n","        #sudah dari awal kata tersebut adalah kata dasar\n","        elif string_split[i] == hasil_stem[i] and hasil_stem[i] == actual_word[i]:\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Idris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'Kata Dasar'}\n","            df = df.append(new_row, ignore_index=True)\n","    \n","        #kata tersebut berhasil distemming dengan baik\n","        elif string_split[i] != hasil_stem[i] and hasil_stem[i] == actual_word[i]:\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Idris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'Benar'}\n","            df = df.append(new_row, ignore_index=True)\n","\n","        #Kata tersebut tidak berubah dari awal (tidak terstemming)\n","        elif string_split[i] == hasil_stem[i] and hasil_stem[i] != actual_word[i]:\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Idris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'Unchange'}\n","            df = df.append(new_row, ignore_index=True)\n","        \n","        #kata tersebut berhasil distemming tetapi hasilnya salah\n","        elif string_split[i] != hasil_stem[i] and len(hasil_stem[i]) == len(actual_word[i]):\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Idris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'Spelling exception'}\n","            df = df.append(new_row, ignore_index=True)\n","        \n","        #kata tersebut berhasil distemming tetapi hasilnya overstemming\n","        elif string_split[i] != hasil_stem[i] and len(hasil_stem[i]) < len(actual_word[i]):\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Idris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'Overstemming'}\n","            df = df.append(new_row, ignore_index=True)\n","        \n","        #kata tersebut berhasil distemming tetapi hasilnya understemming\n","        elif string_split[i] != hasil_stem[i] and len(hasil_stem[i]) > len(actual_word[i]):\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Idris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'Understemming'}\n","            df = df.append(new_row, ignore_index=True)\n","\n","        #jika tidak masuk semua kondisi diatas\n","        else:\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Idris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'None'}\n","            df = df.append(new_row, ignore_index=True)\n","    \n","    #export ke file csv\n","    hasil_path = os.path.join(os.getcwd(), 'hasil_idris')\n","    df.to_csv(os.path.join(hasil_path, 'Perbandingan Stemming Idris '+str(file[:-4])+'.csv'), index=False)\n","    return df"],"id":"043d5204","execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"49e308d2"},"source":["## HASIL"],"id":"49e308d2"},{"cell_type":"code","metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"id":"dd43bca0","executionInfo":{"status":"ok","timestamp":1628351559950,"user_tz":-420,"elapsed":19452,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}},"outputId":"67dd3a0b-e71e-4e77-e2b8-e222f8d425a2"},"source":["#dapatkan list file dari test data\n","test_data_path = os.path.join(os.getcwd(), 'test_data')\n","test_data_filelist = os.listdir(test_data_path)\n","test_data_filelist_sorted = sorted(test_data_filelist, key=lambda x: int(x.split('.')[0]))\n","\n","#path dari actual word\n","actual_data_path = os.path.join(os.getcwd(), 'actual_word')\n","\n","#path hasil idris\n","hasil_path = os.path.join(os.getcwd(), 'hasil_idris')\n","\n","for file in test_data_filelist_sorted:\n","    print(file)\n","    \n","    #preprocessing\n","    txt = open(os.path.join(test_data_path, file), encoding='cp1252')\n","    # txt = open(os.path.join(test_data_path, file))\n","    txt = Case_folding(txt.read())\n","    txt = txt.split()\n","    len_txt = len(txt)\n","    txt = removeStopword(txt)\n","    \n","    hasil_stem_idris = []\n","\n","    Kata_baru = txt[0]\n","\n","    #stemming idris\n","    string_split = Kata_baru.split(' ')\n","    with open(os.path.join(hasil_path, 'Hasil Stemming Idris '+str(file[:-4])+'.txt'), 'w') as i:\n","        for a in string_split:\n","            st = stemming_idris(a)\n","            hasil_stem_idris.append(st)\n","            i.write(st)\n","            i.write('\\n')\n","    \n","    # hasil_stem_idris\n","#     jumlah_kata = len(string_split)\n","    jumlah_stem = len(hasil_stem_idris)\n","    kata_benar = sum('(Kata Salah)' not in x for x in hasil_stem_idris)\n","    kata_salah = sum('(Kata Salah)' in x for x in hasil_stem_idris)\n","    acc = round((kata_benar/jumlah_stem)*100, 3)\n","\n","    print(\"  jumlah total Kata \\t=\", str(len_txt))\n","    print(\"  jumlah stemming Kata \\t=\", str(jumlah_stem))\n","    print(\"  jumlah Kata benar \\t=\", str(kata_benar))\n","    print(\"  jumlah Kata salah \\t=\", str(kata_salah))\n","    print(\"  Akurasi stemming \\t= {}%\\n\".format(acc))\n","    \n","    #menghilangkan kata yang mengandung tulisan (Kata Salah) dari list ex: yunani (Kata Salah) ==> yunani\n","    hasil_stem_idris_dasar = [x[:-13] if 'Salah' in x else x for x in hasil_stem_idris]\n","    \n","    #mengambil list actual word (kata yang benar)\n","    actual_word = open(os.path.join(actual_data_path, file))\n","    actual_word = [line.rstrip('\\n') for line in actual_word]\n","    \n","    #perbandingan hasil stemming inidris dengan actual word\n","    df = create_output(string_split, hasil_stem_idris_dasar, actual_word, file)\n","    \n","    print(\"  Hasil Perbandingan Dengan Data Sebenarnya\")\n","    print(\"   Kata dasar benar tanpa imbuhan \\t\\t\\t\\t(benar) =\", len(df[df.Hasil == 'Kata Dasar']))\n","    print(\"   Kata dasar hasil stemming  \\t\\t\\t\\t\\t(benar) =\", len(df[df.Hasil == 'Benar']))\n","    print(\"   Bukan Kata Berimbuhan \\t\\t\\t\\t\\t(salah) =\", len(df[df.Hasil == 'Bukan Kata Berimbuhan']))\n","    print(\"   Kata yang tidak berubah(Unchange) \\t\\t\\t\\t(salah) =\", len(df[df.Hasil == 'Unchange']))\n","    print(\"   Kata hasil Stemming yang salah(spelling exception) \\t\\t(benar) =\", len(df[df.Hasil == 'Spelling exception']))\n","    print(\"   Kata hasil stemming yg understemming \\t\\t\\t(benar) =\", len(df[df.Hasil == 'Understemming']))\n","    print(\"   Kata hasil stemming yg overstemming \\t\\t\\t\\t(benar) =\", len(df[df.Hasil == 'Overstemming']), '\\n')\n","        "],"id":"dd43bca0","execution_count":33,"outputs":[{"output_type":"stream","text":["1.Percy Jackson dan Pencuri Petir.txt\n","  jumlah total Kata \t= 239\n","  jumlah stemming Kata \t= 123\n","  jumlah Kata benar \t= 96\n","  jumlah Kata salah \t= 27\n","  Akurasi stemming \t= 78.049%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 66\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 28\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 8\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 19\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 1\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 0\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 1 \n","\n","2.The Hunger Games.txt\n","  jumlah total Kata \t= 261\n","  jumlah stemming Kata \t= 146\n","  jumlah Kata benar \t= 118\n","  jumlah Kata salah \t= 28\n","  Akurasi stemming \t= 80.822%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 71\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 43\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 9\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 19\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 0\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 1\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 3 \n","\n","3.Harry Potter Dan Piala Api.txt\n","  jumlah total Kata \t= 323\n","  jumlah stemming Kata \t= 165\n","  jumlah Kata benar \t= 137\n","  jumlah Kata salah \t= 28\n","  Akurasi stemming \t= 83.03%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 89\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 44\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 17\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 12\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 1\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 0\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 2 \n","\n","4.Dalam Mihrab Cinta.txt\n","  jumlah total Kata \t= 510\n","  jumlah stemming Kata \t= 233\n","  jumlah Kata benar \t= 188\n","  jumlah Kata salah \t= 45\n","  Akurasi stemming \t= 80.687%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 109\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 67\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 23\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 22\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 0\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 2\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 10 \n","\n","5.Harry Potter Dan Batu Bertuah.txt\n","  jumlah total Kata \t= 606\n","  jumlah stemming Kata \t= 311\n","  jumlah Kata benar \t= 232\n","  jumlah Kata salah \t= 79\n","  Akurasi stemming \t= 74.598%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 144\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 75\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 35\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 44\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 2\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 0\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 11 \n","\n","6.Percy Jackson dan Lautan Monster.txt\n","  jumlah total Kata \t= 2190\n","  jumlah stemming Kata \t= 1116\n","  jumlah Kata benar \t= 887\n","  jumlah Kata salah \t= 229\n","  Akurasi stemming \t= 79.48%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 514\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 336\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 106\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 124\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 15\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 2\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 19 \n","\n","7.Mentari Cahaya dan Cinta.txt\n","  jumlah total Kata \t= 1356\n","  jumlah stemming Kata \t= 757\n","  jumlah Kata benar \t= 504\n","  jumlah Kata salah \t= 253\n","  Akurasi stemming \t= 66.579%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 340\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 148\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 162\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 87\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 6\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 1\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 13 \n","\n","8.Koma.txt\n","  jumlah total Kata \t= 1201\n","  jumlah stemming Kata \t= 551\n","  jumlah Kata benar \t= 414\n","  jumlah Kata salah \t= 137\n","  Akurasi stemming \t= 75.136%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 232\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 159\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 41\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 96\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 8\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 5\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 10 \n","\n","9.Perahu Kertas.txt\n","  jumlah total Kata \t= 782\n","  jumlah stemming Kata \t= 440\n","  jumlah Kata benar \t= 352\n","  jumlah Kata salah \t= 88\n","  Akurasi stemming \t= 80.0%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 200\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 114\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 52\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 37\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 4\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 2\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 31 \n","\n","10.Demonglass.txt\n","  jumlah total Kata \t= 975\n","  jumlah stemming Kata \t= 477\n","  jumlah Kata benar \t= 363\n","  jumlah Kata salah \t= 114\n","  Akurasi stemming \t= 76.101%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 186\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 160\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 47\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 66\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 6\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 1\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 11 \n","\n"],"name":"stdout"}]}]}