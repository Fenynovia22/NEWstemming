{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"PENGUJIAN_INIDRISnew.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"a5dee1f2","executionInfo":{"status":"ok","timestamp":1628352225879,"user_tz":-420,"elapsed":2382,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["import re\n","import nltk\n","import os\n","import pandas as pd\n","import numpy as np "],"id":"a5dee1f2","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hHEMH5wfG7-T","executionInfo":{"status":"ok","timestamp":1628352244772,"user_tz":-420,"elapsed":18896,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}},"outputId":"8b7f4f92-a401-4931-d55f-c6d4fd5f394c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"hHEMH5wfG7-T","execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bL1HxGhsHBV7","executionInfo":{"status":"ok","timestamp":1628352244773,"user_tz":-420,"elapsed":29,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}},"outputId":"8fede645-fd4f-4dc4-aabc-34a46b8a1541"},"source":["cd '/content/drive/My Drive/Colab Notebooks/data_skripsi'"],"id":"bL1HxGhsHBV7","execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/data_skripsi\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2EYpxLV7HKFs","executionInfo":{"status":"ok","timestamp":1628352245325,"user_tz":-420,"elapsed":568,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}},"outputId":"32163061-8c25-4e42-d050-59cbb01419ef"},"source":["!ls"],"id":"2EYpxLV7HKFs","execution_count":4,"outputs":[{"output_type":"stream","text":[" actual_word\t\t\t   kata_dasar_db.txt\n"," hasil_idris\t\t\t   PENGUJIAN_IDRISnew.ipynb\n"," hasil_inidris\t\t\t   PENGUJIAN_INIDRISnew.ipynb\n","'Hasil perbandingan Idris.csv'\t  'Perbandingan Stemming Idris.csv'\n","'Hasil perbandingan Inidris.csv'  'Perbandingan Stemming Inidris.csv'\n"," IDRIS.ipynb\t\t\t   stopwords2.txt\n"," INIDRIS.ipynb\t\t\t   stopwords.txt\n"," katadasarbahasaindonesia.txt\t   test_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6d3d76a","executionInfo":{"status":"ok","timestamp":1628352245326,"user_tz":-420,"elapsed":27,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}},"outputId":"9cdd749a-f94a-4d58-a484-4b70ede17a51"},"source":["stopword = open(\"stopwords2.txt\", 'r').read() \n","stopword = stopword.split(\"\\n\")\n","stopword[:5]"],"id":"e6d3d76a","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ada', 'adalah', 'adanya', 'adapun', 'agak']"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"d112f189","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628352245327,"user_tz":-420,"elapsed":19,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}},"outputId":"7c755dff-8697-4bf4-9907-b23648644270"},"source":["kata_dasar = open(\"kata_dasar_db.txt\", 'r').read()\n","kata_dasar = kata_dasar.split(\"\\n\")\n","\n","kamus = []\n","for i in kata_dasar:\n","    kata = \"{}\".format(i)\n","    kata = kata.replace(\"(Nomina)\", \"\")\n","    kata = kata.replace(\"(Adjektiva)\", \"\")\n","    kata = kata.replace(\"(Adverbia)\", \"\")\n","    kata = kata.replace(\"(Numeralia)\", \"\")\n","    kata = kata.replace(\"(Pronomina)\", \"\")\n","    kata = kata.replace(\"(Verba)\", \"\")\n","    kata = kata.replace(\"(Preposisi)\", \"\")\n","    kata = kata.replace(\"(Interjeksi)\", \"\")\n","    kata = kata.replace(\"(Konjungsi)\", \"\")\n","    kata = kata.replace(\"(Lain-lain)\", \"\")\n","    kata = kata.replace(\"\\n\", \"\")\n","    kata = kata.rstrip()\n","    kamus.append(kata)\n","kamus[:5]"],"id":"d112f189","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['a', 'ab', 'aba', 'aba-aba', 'abad']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"bcc7850b","executionInfo":{"status":"ok","timestamp":1628352245329,"user_tz":-420,"elapsed":15,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["# fungsi untuk mengecek kata dalam tabel dictionary\n","def cekKamus_idris_modif(kata):\n","    if kata in kamus:\n","        return kata\n","    else:\n","        status = 0\n","    return status"],"id":"bcc7850b","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"07d1e718","executionInfo":{"status":"ok","timestamp":1628352245744,"user_tz":-420,"elapsed":426,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["# Hapus Derivation Prefix (\"di-\", \"ke-\", \"se-\", \"te-\", \"be-\", \"me-\", atau \"pe-\")\n","def del_derivation_prefix_idris_modif(kata):\n","    kataAsal = kata\n","    # /* —— Tentukan Tipe Awalan ————*/\n","    if(re.search(r\"^(di|[ks]e)\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"^(di|[ks]e)\", '', kata, re.IGNORECASE)\n","        if(cekKamus_idris_modif(_kata)):\n","            return _kata\n","\n","        _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","        if(cekKamus_idris_modif(_kata_)):\n","            return _kata_\n","\n","        if(re.search(r\"^(diper)\", kata, re.IGNORECASE)):\n","            _kata = re.sub(r\"^(diper)\", '', kata, re.IGNORECASE)\n","            _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","            if(cekKamus_idris_modif(_kata_)):\n","                return _kata_\n","\n","        if(re.search(r\"^(ke[bt]er)\", kata, re.IGNORECASE)):\n","            _kata = re.sub(r\"^(ke[bt]er)\", '', kata, re.IGNORECASE)\n","            _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","            if(cekKamus_idris_modif(_kata_)):\n","                return _kata_\n","\n","    if(re.search(r\"^([bt]e)\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"^([bt]e)\", '', kata, re.IGNORECASE)\n","        if(cekKamus_idris_modif(_kata)):\n","            return _kata\n","\n","        _kata = re.sub(r\"^([bt]e[lr])\", '', kata, re.IGNORECASE)\n","        if(cekKamus_idris_modif(_kata)):\n","            return _kata\n","\n","        _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","        if(cekKamus_idris_modif(_kata_)):\n","            return _kata\n","\n","    if(re.search(r\"^([mp]e)\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"^([mp]e)\", '', kata)\n","        if(cekKamus_idris_modif(_kata)):\n","            return _kata\n","        _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","        if(cekKamus_idris_modif(_kata_)):\n","            return _kata_\n","\n","        if(re.search(r\"^(memper)\", kata, re.IGNORECASE)):\n","            _kata = re.sub(r\"^(memper)\", '', kata, re.IGNORECASE)\n","            if(cekKamus_idris_modif(_kata)):\n","                return _kata\n","\n","            _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","            if(cekKamus_idris_modif(_kata_)):\n","                return _kata_\n","\n","        if(re.search(r\"^([mp]eng)\", kata, re.IGNORECASE)):\n","            _kata = re.sub(r\"^([mp]eng)\", '', kata, re.IGNORECASE)\n","            if(cekKamus_idris_modif(_kata)):\n","                return _kata\n","\n","            _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","            if(cekKamus_idris_modif(_kata_)):\n","                return _kata_\n","\n","            _kata = re.sub(r\"^([mp]eng)\", 'k', kata, re.IGNORECASE)\n","            if(cekKamus_idris_modif(_kata)):\n","                return _kata\n","\n","            _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","            if(cekKamus_idris_modif(_kata_)):\n","                return _kata_\n","\n","        if(re.search(r\"^([mp]eny)\", kata, re.IGNORECASE)):\n","            _kata = re.sub(r\"^([mp]eny)\", 's', kata, re.IGNORECASE)\n","            if(cekKamus_idris_modif(_kata)):\n","                return _kata\n","            _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","            if(cekKamus_idris_modif(_kata_)):\n","                return _kata_\n","\n","        if(re.search(r\"^([mp]e[lr])\", kata, re.IGNORECASE)):\n","            _kata = re.sub(r\"^([mp]e[lr])\", '', kata, re.IGNORECASE)\n","            if(cekKamus_idris_modif(_kata)):\n","                return _kata\n","            _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","            if(cekKamus_idris_modif(_kata_)):\n","                return _kata_\n","\n","        if(re.search(r\"^([mp]en)\", kata, re.IGNORECASE)):\n","            _kata = re.sub(r\"^([mp]en)\", 't', kata, re.IGNORECASE)\n","            if(cekKamus_idris_modif(_kata)):\n","                return _kata\n","            _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","            if(cekKamus_idris_modif(_kata_)):\n","                return _kata_\n","            _kata = re.sub(r\"^([mp]en)\", '', kata, re.IGNORECASE)\n","            if(cekKamus_idris_modif(_kata)):\n","                return _kata\n","            _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","            if(cekKamus_idris_modif(_kata_)):\n","                return _kata_\n","\n","        if(re.search(r\"^([mp]em)\", kata, re.IGNORECASE)):\n","            _kata = re.sub(r\"^([mp]em)\", 'p', kata, re.IGNORECASE)\n","            if(cekKamus_idris_modif(_kata)):\n","                return _kata\n","            _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","            if(cekKamus_idris_modif(_kata_)):\n","                return _kata_\n","            _kata = re.sub(r\"^([mp]em)\", '', kata, re.IGNORECASE)\n","            if(cekKamus_idris_modif(_kata)):\n","                return _kata\n","            _kata_ = del_derivation_suffixes_idris_modif(_kata)\n","            if(cekKamus_idris_modif(_kata_)):\n","                return _kata_\n","\n","    return kataAsal"],"id":"07d1e718","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ebca8f74","executionInfo":{"status":"ok","timestamp":1628352245745,"user_tz":-420,"elapsed":11,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["# Cek Prefix Disallowed Sufixes (Kombinasi Awalan dan Akhiran yang tidak diizinkan)\n","def cek_prefix_disallowed_sufiks_idris(kata):\n","    kataAsal = kata\n","    # r\"^(ber)[[:alpha:]](lah|an)$\"\n","    if(re.search(r\"^(ber)[^\\W\\d_](lah|an)$\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"^(ber)\", '', kata, re.IGNORECASE)\n","        return _kata\n","    # ^(men|di|pe|ter)[[:alpha:]](i)\n","    if (re.search(r\"^(men|di|pe|ter)[^\\W\\d_](i)$\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"^(men|di|pe|ter)\", '', kata, re.IGNORECASE)\n","        return _kata\n","    return kataAsal"],"id":"ebca8f74","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"49228a96","executionInfo":{"status":"ok","timestamp":1628352245745,"user_tz":-420,"elapsed":9,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["def del_inflection_suffixes_idris_modif(kata):\n","    kataAsal = kata\n","\n","    if(re.search(r\"([km]u|nya|[kl]ah|pun)$\", kata, re.IGNORECASE)):\n","        _kata = re.sub(r\"([km]u|nya|[kl]ah|pun)$\", '', kata)\n","        return _kata\n","    return kataAsal"],"id":"49228a96","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3a7cb8a","executionInfo":{"status":"ok","timestamp":1628352245746,"user_tz":-420,"elapsed":9,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["def del_derivation_suffixes_idris_modif(kata):\n","    kataAsal = kata\n","\n","    if(re.search(r\"(i|an)$\", kata)):\n","        _kata = re.sub(r\"(i|an)$\", '', kata)\n","        if(cekKamus_idris_modif(_kata)):\n","            return _kata\n","        elif(re.search(r\"(kan)$\", kata)):\n","            _kata = re.sub(r\"(kan)$\", '', kata)\n","            if(cekKamus_idris_modif(_kata)):\n","                return _kata\n","    # /*– Jika Tidak ditemukan di kamus –*/\n","    return kataAsal"],"id":"c3a7cb8a","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"d872ef36","executionInfo":{"status":"ok","timestamp":1628352245746,"user_tz":-420,"elapsed":9,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["# fungsi pencarian akar kata\n","def stemming_idris_modif(kata):\n","    kataAsal = kata\n","    # print(\"1\"+str(kata))\n","    if (cekKamus_idris_modif(kata) != 0):  # cek kamus\n","        # Jika Ada maka kata tersebut adalah kata dasar\n","        return kata\n","    else:  # jika tidak ada dalam kamus maka dilakukan stemming\n","        kata = del_derivation_prefix_idris_modif(kata)\n","        if(cekKamus_idris_modif(kata)):\n","            return kata\n","\n","        kata = del_inflection_suffixes_idris_modif(kata)\n","        if(cekKamus_idris_modif(kata)):\n","            return kata\n","\n","        kata = del_derivation_suffixes_idris_modif(kata)\n","        if(cekKamus_idris_modif(kata)):\n","            return kata\n","        else:\n","            return kataAsal+\" \"+\"(Kata Salah)\""],"id":"d872ef36","execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f5092b6b"},"source":["## CASE FOLDING"],"id":"f5092b6b"},{"cell_type":"code","metadata":{"scrolled":true,"id":"81c75553","executionInfo":{"status":"ok","timestamp":1628352245746,"user_tz":-420,"elapsed":8,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["def Case_folding(casefold):\n","    casefold = casefold.lower()\n","    # Remove angka termasuk angka yang berada dalam string\n","    # Remove non ASCII chars\n","    casefold = re.sub(r'[^\\x00-\\x7f]', r'', casefold)\n","    casefold = re.sub(r'(\\\\u[0-9A-Fa-f]+)', r'', casefold)\n","    casefold = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", casefold)\n","    casefold = re.sub(r'\\\\u\\w\\w\\w\\w', '', casefold)\n","    # Remove link web\n","    casefold = re.sub(r'http\\S+', '', casefold)\n","    # Remove @username\n","    casefold = re.sub('@[^\\s]+', '', casefold)\n","    # Remove #tagger\n","    casefold = re.sub(r'#([^\\s]+)', '', casefold)\n","    # Remove simbol, angka dan karakter aneh\n","    casefold = re.sub(r\"[.,:;+!\\-_<^/=?\\\"'\\(\\)\\d\\*]\", \" \", casefold)\n","    return casefold"],"id":"81c75553","execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3e5a8f42"},"source":["## TOKENIZING"],"id":"3e5a8f42"},{"cell_type":"code","metadata":{"scrolled":true,"id":"0d711455","executionInfo":{"status":"ok","timestamp":1628352245747,"user_tz":-420,"elapsed":9,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["# Tokenizing = Kata.split()\n","# print(Tokenizing)"],"id":"0d711455","execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bb95bc35"},"source":["## STOPWORD REMOVING"],"id":"bb95bc35"},{"cell_type":"code","metadata":{"id":"1c224461","executionInfo":{"status":"ok","timestamp":1628352245747,"user_tz":-420,"elapsed":8,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["def removeStopword(remove_stop):\n","    Stopword_data = open('stopwords2.txt', 'r').read().split()\n","    Kata_baru = []\n","    content = []\n","    filteredtext = [word for word in remove_stop if word not in Stopword_data]\n","    content.append(\" \".join(filteredtext))\n","    remove_stop = content\n","    return remove_stop"],"id":"1c224461","execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"887b8978"},"source":["## FUNGSI PERBANDINGAN HASIL"],"id":"887b8978"},{"cell_type":"code","metadata":{"id":"cc271d9f","executionInfo":{"status":"ok","timestamp":1628352245748,"user_tz":-420,"elapsed":8,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}}},"source":["def create_output(string_split, hasil_stem, actual_word, filename):\n","    #membuat dataframe dengan nama kolom dibawah ini\n","    df = pd.DataFrame(columns =  [\"Kata Asli\", \"Stemming Inidris\", \"Stemming Asli\", \"Hasil\"])\n","    for i in range(len(string_split)):\n","        #jika kata tersebut adalah kata asing, nama kota, nama orang dsb\n","        if '(' in actual_word[i] and string_split[i] == hasil_stem[i] and hasil_stem[i] == actual_word[i][:actual_word[i].find('(')]:\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Inidris':hasil_stem[i], 'Stemming Asli':actual_word[i][:actual_word[i].find('(')], 'Hasil':'Bukan Kata Berimbuhan'}\n","            df = df.append(new_row, ignore_index=True)\n","        \n","        elif'(' in actual_word[i] and string_split[i] == hasil_stem[i] and hasil_stem[i] != actual_word[i][:actual_word[i].find('(')]:\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Inidris':hasil_stem[i], 'Stemming Asli':actual_word[i][:actual_word[i].find('(')], 'Hasil':'Unchange'}\n","            df = df.append(new_row, ignore_index=True)\n","        \n","        #sudah dari awal kata tersebut adalah kata dasar\n","        elif string_split[i] == hasil_stem[i] and hasil_stem[i] == actual_word[i]:\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Inidris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'Kata Dasar'}\n","            df = df.append(new_row, ignore_index=True)\n","            \n","        #kata tersebut berhasil distemming dengan baik\n","        elif string_split[i] != hasil_stem[i] and hasil_stem[i] == actual_word[i]:\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Inidris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'Benar'}\n","            df = df.append(new_row, ignore_index=True)\n","        \n","        #Kata tersebut tidak berubah dari awal (tidak terstemming)\n","        elif string_split[i] == hasil_stem[i] and hasil_stem[i] != actual_word[i]:\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Inidris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'Unchange'}\n","            df = df.append(new_row, ignore_index=True)\n","        \n","        #kata tersebut berhasil distemming tetapi hasilnya salah\n","        elif string_split[i] != hasil_stem[i] and len(hasil_stem[i]) == len(actual_word[i]):\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Inidris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'Spelling exception'}\n","            df = df.append(new_row, ignore_index=True)\n","\n","        #kata tersebut berhasil distemming tetapi hasilnya overstemming\n","        elif string_split[i] != hasil_stem[i] and len(hasil_stem[i]) < len(actual_word[i]):\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Inidris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'Overstemming'}\n","            df = df.append(new_row, ignore_index=True)\n","        \n","        #kata tersebut berhasil distemming tetapi hasilnya understemming\n","        elif string_split[i] != hasil_stem[i] and len(hasil_stem[i]) > len(actual_word[i]):\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Inidris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'Understemming'}\n","            df = df.append(new_row, ignore_index=True)\n","        \n","        #jika tidak masuk semua kondisi diatas\n","        else:\n","            new_row = {'Kata Asli':string_split[i], 'Stemming Inidris':hasil_stem[i], 'Stemming Asli':actual_word[i], 'Hasil':'None'}\n","            df = df.append(new_row, ignore_index=True)\n","    \n","    #export ke file csv\n","    hasil_path = os.path.join(os.getcwd(), 'hasil_inidris')\n","    df.to_csv(os.path.join(hasil_path, 'Perbandingan Stemming Inidris '+str(file[:-4])+'.csv'), index=False)\n","    return df"],"id":"cc271d9f","execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d5584eed"},"source":["## HASIL"],"id":"d5584eed"},{"cell_type":"code","metadata":{"scrolled":false,"id":"ac3f04d1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628352271512,"user_tz":-420,"elapsed":25772,"user":{"displayName":"Feny Novia Rahayu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgbKbXUEvA17wFD9nddv2hy21TGisYjgp5hm4=s64","userId":"08761188267575270071"}},"outputId":"61ae2849-123d-499e-8fbb-44807b9b64ba"},"source":["#dapatkan list file dari test data\n","test_data_path = os.path.join(os.getcwd(), 'test_data')\n","test_data_filelist = os.listdir(test_data_path)\n","test_data_filelist_sorted = sorted(test_data_filelist, key=lambda x: int(x.split('.')[0]))\n","\n","#path dari actual word\n","actual_data_path = os.path.join(os.getcwd(), 'actual_word')\n","\n","#path hasil idris\n","hasil_path = os.path.join(os.getcwd(), 'hasil_inidris')\n","\n","for file in test_data_filelist_sorted:\n","    print(file)\n","    \n","    #preprocessing\n","    txt = open(os.path.join(test_data_path, file), encoding='cp1252')\n","    # txt = open(os.path.join(test_data_path, file))\n","    txt = Case_folding(txt.read())\n","    txt = txt.split()\n","    len_txt = len(txt)\n","    txt = removeStopword(txt)\n","    \n","    hasil_stem_in_idris = []\n","\n","    Kata_baru = txt[0]\n","\n","    #stemming inidris\n","    string_split = Kata_baru.split(' ')\n","    with open(os.path.join(hasil_path, 'Hasil Stemming Idris '+str(file[:-4])+'.txt'), 'w') as i:\n","        for a in string_split:\n","            st = stemming_idris_modif(a)\n","            hasil_stem_in_idris.append(st)\n","            i.write(st)\n","            i.write('\\n')\n","    \n","    # hasil stem inidris\n","    jumlah_kata = len(string_split)\n","    jumlah_stem = len(hasil_stem_in_idris)\n","    kata_benar = sum('(Kata Salah)' not in x for x in hasil_stem_in_idris)\n","    kata_salah = sum('(Kata Salah)' in x for x in hasil_stem_in_idris)\n","    acc = round((kata_benar/jumlah_stem)*100, 3)\n","\n","    print(\"  jumlah total Kata \\t=\", str(len_txt))\n","    print(\"  jumlah stemming Kata \\t=\", str(jumlah_stem))\n","    print(\"  jumlah Kata benar \\t=\", str(kata_benar))\n","    print(\"  jumlah Kata salah \\t=\", str(kata_salah))\n","    print(\"  Akurasi stemming \\t= {}%\\n\".format(acc))\n","    \n","    #menghilangkan kata yang mengandung tulisan (Kata Salah) dari list ex: yunani (Kata Salah) ==> yunani\n","    hasil_stem_in_idris_dasar = [x[:-13] if 'Salah' in x else x for x in hasil_stem_in_idris]\n","    \n","    #mengambil list actual word (kata yang benar)\n","    actual_word = open(os.path.join(actual_data_path, file))\n","    actual_word = [line.rstrip('\\n') for line in actual_word]\n","    \n","    #perbandingan hasil stemming inidris dengan actual word\n","    df = create_output(string_split, hasil_stem_in_idris_dasar, actual_word, file)\n","    \n","    print(\"  Hasil Perbandingan Dengan Data Sebenarnya\")\n","    print(\"   Kata dasar benar tanpa imbuhan \\t\\t\\t\\t(benar) =\", len(df[df.Hasil == 'Kata Dasar']))\n","    print(\"   Kata dasar hasil stemming  \\t\\t\\t\\t\\t(benar) =\", len(df[df.Hasil == 'Benar']))\n","    print(\"   Bukan Kata Berimbuhan \\t\\t\\t\\t\\t(salah) =\", len(df[df.Hasil == 'Bukan Kata Berimbuhan']))\n","    print(\"   Kata yang tidak berubah(Unchange) \\t\\t\\t\\t(salah) =\", len(df[df.Hasil == 'Unchange']))\n","    print(\"   Kata hasil Stemming yang salah(spelling exception) \\t\\t(benar) =\", len(df[df.Hasil == 'Spelling exception']))\n","    print(\"   Kata hasil stemming yg understemming \\t\\t\\t(benar) =\", len(df[df.Hasil == 'Understemming']))\n","    print(\"   Kata hasil stemming yg overstemming \\t\\t\\t\\t(benar) =\", len(df[df.Hasil == 'Overstemming']), '\\n')\n","        "],"id":"ac3f04d1","execution_count":17,"outputs":[{"output_type":"stream","text":["1.Percy Jackson dan Pencuri Petir.txt\n","  jumlah total Kata \t= 239\n","  jumlah stemming Kata \t= 123\n","  jumlah Kata benar \t= 106\n","  jumlah Kata salah \t= 17\n","  Akurasi stemming \t= 86.179%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 66\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 39\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 8\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 9\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 0\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 1\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 0 \n","\n","2.The Hunger Games.txt\n","  jumlah total Kata \t= 261\n","  jumlah stemming Kata \t= 146\n","  jumlah Kata benar \t= 125\n","  jumlah Kata salah \t= 21\n","  Akurasi stemming \t= 85.616%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 71\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 51\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 9\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 12\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 1\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 1\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 1 \n","\n","3.Harry Potter Dan Piala Api.txt\n","  jumlah total Kata \t= 323\n","  jumlah stemming Kata \t= 165\n","  jumlah Kata benar \t= 145\n","  jumlah Kata salah \t= 20\n","  Akurasi stemming \t= 87.879%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 89\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 52\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 17\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 4\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 0\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 1\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 2 \n","\n","4.Dalam Mihrab Cinta.txt\n","  jumlah total Kata \t= 510\n","  jumlah stemming Kata \t= 233\n","  jumlah Kata benar \t= 192\n","  jumlah Kata salah \t= 41\n","  Akurasi stemming \t= 82.403%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 109\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 78\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 23\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 18\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 0\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 2\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 3 \n","\n","5.Harry Potter Dan Batu Bertuah.txt\n","  jumlah total Kata \t= 606\n","  jumlah stemming Kata \t= 311\n","  jumlah Kata benar \t= 256\n","  jumlah Kata salah \t= 55\n","  Akurasi stemming \t= 82.315%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 144\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 107\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 35\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 20\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 0\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 1\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 4 \n","\n","6.Percy Jackson dan Lautan Monster.txt\n","  jumlah total Kata \t= 2190\n","  jumlah stemming Kata \t= 1116\n","  jumlah Kata benar \t= 944\n","  jumlah Kata salah \t= 172\n","  Akurasi stemming \t= 84.588%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 514\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 408\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 106\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 67\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 6\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 5\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 10 \n","\n","7.Mentari Cahaya dan Cinta.txt\n","  jumlah total Kata \t= 1356\n","  jumlah stemming Kata \t= 757\n","  jumlah Kata benar \t= 524\n","  jumlah Kata salah \t= 233\n","  Akurasi stemming \t= 69.221%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 340\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 176\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 162\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 67\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 2\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 3\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 7 \n","\n","8.Koma.txt\n","  jumlah total Kata \t= 1201\n","  jumlah stemming Kata \t= 551\n","  jumlah Kata benar \t= 442\n","  jumlah Kata salah \t= 109\n","  Akurasi stemming \t= 80.218%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 232\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 205\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 41\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 68\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 1\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 0\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 4 \n","\n","9.Perahu Kertas.txt\n","  jumlah total Kata \t= 782\n","  jumlah stemming Kata \t= 440\n","  jumlah Kata benar \t= 378\n","  jumlah Kata salah \t= 62\n","  Akurasi stemming \t= 85.909%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 200\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 145\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 52\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 11\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 2\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 2\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 28 \n","\n","10.Demonglass.txt\n","  jumlah total Kata \t= 975\n","  jumlah stemming Kata \t= 477\n","  jumlah Kata benar \t= 399\n","  jumlah Kata salah \t= 78\n","  Akurasi stemming \t= 83.648%\n","\n","  Hasil Perbandingan Dengan Data Sebenarnya\n","   Kata dasar benar tanpa imbuhan \t\t\t\t(benar) = 186\n","   Kata dasar hasil stemming  \t\t\t\t\t(benar) = 205\n","   Bukan Kata Berimbuhan \t\t\t\t\t(salah) = 47\n","   Kata yang tidak berubah(Unchange) \t\t\t\t(salah) = 30\n","   Kata hasil Stemming yang salah(spelling exception) \t\t(benar) = 0\n","   Kata hasil stemming yg understemming \t\t\t(benar) = 0\n","   Kata hasil stemming yg overstemming \t\t\t\t(benar) = 9 \n","\n"],"name":"stdout"}]}]}